"""
Cortex Analyst App 
====================
ã“ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¯ã€è‡ªç„¶è¨€èªã‚’ä½¿ç”¨ã—ã¦ãƒ‡ãƒ¼ã‚¿ã¨å¯¾è©±ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚
"""

import json  # JSONãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ã™ã‚‹ãŸã‚ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
import time
from typing import Dict, List, Optional, Tuple

import _snowflake  # Snowflakeå›ºæœ‰ã®APIã¨ã®é€£æºç”¨
import pandas as pd
import streamlit as st  # Webã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³æ§‹ç¯‰ç”¨ã®Streamlitãƒ©ã‚¤ãƒ–ãƒ©ãƒª
from snowflake.snowpark.context import (
    get_active_session,
)  # Snowflakeã‚»ãƒƒã‚·ãƒ§ãƒ³ã¨ã®é€£æºç”¨
from snowflake.snowpark.exceptions import SnowparkSQLException

# ä½¿ç”¨å¯èƒ½ãªã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹ã®ãƒªã‚¹ãƒˆï¼ˆå½¢å¼: <DATABASE>.<SCHEMA>.<STAGE>/<FILE-NAME>ï¼‰
# å„ãƒ‘ã‚¹ã¯ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒ¢ãƒ‡ãƒ«ã‚’å®šç¾©ã™ã‚‹YAMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’æŒ‡ã—ã¾ã™
AVAILABLE_SEMANTIC_MODELS_PATHS = [
# Replace variables with your environment.
# File created by semantic-model-generator-main-local
# example "CORTEX_ANALYST_LOCAL.cortex_analyst.RAW_DATA/[your_semantic_model_file_1.yaml"
    "[YOUR_DATABASE].cortex_analyst.RAW_DATA/[your_semantic_model_file_1.yaml",
    "[YOUR_DATABASE].cortex_analyst.RAW_DATA/[your_semantic_model_file_2.yaml"    
]
API_ENDPOINT = "/api/v2/cortex/analyst/message"
API_TIMEOUT = 500000  # ãƒŸãƒªç§’å˜ä½ï¼ˆ10å€ã«æ‹¡å¤§ï¼‰

# ã‚¯ã‚¨ãƒªå®Ÿè¡Œç”¨ã®Snowparkã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’åˆæœŸåŒ–
session = get_active_session()

# ã‚µã‚¸ã‚§ã‚¹ãƒˆç”¨ã®è³ªå•ä¾‹ï¼ˆæ—¥æœ¬èªï¼‰
SUGGESTED_QUESTIONS = [
    "ã“ã®ãƒ‡ãƒ¼ã‚¿ã§ã¯ã©ã®ã‚ˆã†ãªè³ªå•ãŒã§ãã¾ã™ã‹ï¼Ÿ",
    "ãƒ‡ãƒ¼ã‚¿ã®æ¦‚è¦ã‚’æ•™ãˆã¦ãã ã•ã„",
    "æœ€æ–°ã®ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’åˆ†æã—ã¦ãã ã•ã„"
]


def translate_to_japanese(text: str) -> str:
    """
    Snowflake TRANSLATEé–¢æ•°ã‚’ä½¿ç”¨ã—ã¦ãƒ†ã‚­ã‚¹ãƒˆã‚’æ—¥æœ¬èªã«ç¿»è¨³
    
    Args:
        text (str): ç¿»è¨³å¯¾è±¡ã®ãƒ†ã‚­ã‚¹ãƒˆ
        
    Returns:
        str: ç¿»è¨³ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆ
    """
    try:
        # ãƒ†ã‚­ã‚¹ãƒˆãŒæ—¢ã«æ—¥æœ¬èªã®å ´åˆã¯ãã®ã¾ã¾è¿”ã™
        if contains_japanese(text):
            return text
            
        # TRANSLATEé–¢æ•°ã‚’ä½¿ç”¨ã—ã¦è‹±èªã‹ã‚‰æ—¥æœ¬èªã«ç¿»è¨³
        query = f"""
        SELECT SNOWFLAKE.CORTEX.TRANSLATE(
            '{text.replace("'", "''")}',  -- ã‚·ãƒ³ã‚°ãƒ«ã‚¯ã‚©ãƒ¼ãƒˆã‚’ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—
            'en',  -- å…ƒã®è¨€èªï¼ˆè‹±èªï¼‰
            'ja'   -- ç¿»è¨³å…ˆã®è¨€èªï¼ˆæ—¥æœ¬èªï¼‰
        ) as translated_text
        """
        
        result = session.sql(query).collect()
        if result and len(result) > 0:
            return result[0]['TRANSLATED_TEXT']
        else:
            return text  # ç¿»è¨³ã«å¤±æ•—ã—ãŸå ´åˆã¯å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆã‚’è¿”ã™
            
    except Exception as e:
        st.error(f"ç¿»è¨³ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return text  # ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆã‚’è¿”ã™


def contains_japanese(text: str) -> bool:
    """
    ãƒ†ã‚­ã‚¹ãƒˆã«æ—¥æœ¬èªãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
    
    Args:
        text (str): ãƒã‚§ãƒƒã‚¯å¯¾è±¡ã®ãƒ†ã‚­ã‚¹ãƒˆ
        
    Returns:
        bool: æ—¥æœ¬èªãŒå«ã¾ã‚Œã¦ã„ã‚‹å ´åˆTrue
    """
    # ã²ã‚‰ãŒãªã€ã‚«ã‚¿ã‚«ãƒŠã€æ¼¢å­—ã®ç¯„å›²ã‚’ãƒã‚§ãƒƒã‚¯
    for char in text:
        if (
            '\u3040' <= char <= '\u309F' or  # ã²ã‚‰ãŒãª
            '\u30A0' <= char <= '\u30FF' or  # ã‚«ã‚¿ã‚«ãƒŠ
            '\u4E00' <= char <= '\u9FAF'     # æ¼¢å­—
        ):
            return True
    return False


def translate_message_content(content: List[Dict]) -> List[Dict]:
    """
    ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’æ—¥æœ¬èªã«ç¿»è¨³
    
    Args:
        content (List[Dict]): ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
        
    Returns:
        List[Dict]: ç¿»è¨³ã•ã‚ŒãŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
    """
    if not st.session_state.get("japanese_response", True):
        return content
    
    translated_content = []
    
    for item in content:
        if item["type"] == "text":
            # ãƒ†ã‚­ã‚¹ãƒˆã‚’ç¿»è¨³
            translated_text = translate_to_japanese(item["text"])
            translated_content.append({
                "type": "text",
                "text": translated_text
            })
        elif item["type"] == "suggestions":
            # ã‚µã‚¸ã‚§ã‚¹ãƒˆã‚’ç¿»è¨³
            translated_suggestions = []
            for suggestion in item["suggestions"]:
                translated_suggestion = translate_to_japanese(suggestion)
                translated_suggestions.append(translated_suggestion)
            
            translated_content.append({
                "type": "suggestions",
                "suggestions": translated_suggestions
            })
        else:
            # ãã®ä»–ã®ã‚¿ã‚¤ãƒ—ã¯ãã®ã¾ã¾ä¿æŒ
            translated_content.append(item)
    
    return translated_content


def main():
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’åˆæœŸåŒ–
    if "messages" not in st.session_state:
        reset_session_state()
    show_header_and_sidebar()
    if len(st.session_state.messages) == 0:
        # åˆå›ã‚¢ã‚¯ã‚»ã‚¹æ™‚ã«ã‚µã‚¸ã‚§ã‚¹ãƒˆè³ªå•ã‚’è¡¨ç¤º
        display_initial_suggestions()
    display_conversation()
    handle_user_inputs()
    handle_error_notifications()


def reset_session_state():
    """é‡è¦ãªã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹è¦ç´ ã‚’ãƒªã‚»ãƒƒãƒˆ"""
    st.session_state.messages = []  # ä¼šè©±ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä¿å­˜ã™ã‚‹ãƒªã‚¹ãƒˆ
    st.session_state.active_suggestion = None  # ç¾åœ¨é¸æŠã•ã‚Œã¦ã„ã‚‹ã‚µã‚¸ã‚§ã‚¹ãƒˆ


def show_header_and_sidebar():
    """ã‚¢ãƒ—ãƒªã®ãƒ˜ãƒƒãƒ€ãƒ¼ã¨ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‚’è¡¨ç¤º"""
    # ã‚¢ãƒ—ãƒªã®ã‚¿ã‚¤ãƒˆãƒ«ã¨ç´¹ä»‹æ–‡ã‚’è¨­å®š
    st.title("Cortex Analyst")
    st.markdown(
        "Cortex Analystã¸ã‚ˆã†ã“ãï¼ä¸‹è¨˜ã«ã”è³ªå•ã‚’å…¥åŠ›ã—ã¦ã€ãƒ‡ãƒ¼ã‚¿ã¨å¯¾è©±ã—ã¦ãã ã•ã„ã€‚"
    )

    # ãƒªã‚»ãƒƒãƒˆãƒœã‚¿ãƒ³ä»˜ãã®ã‚µã‚¤ãƒ‰ãƒãƒ¼
    with st.sidebar:
        st.selectbox(
            "é¸æŠã•ã‚ŒãŸã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒ¢ãƒ‡ãƒ«:",
            AVAILABLE_SEMANTIC_MODELS_PATHS,
            format_func=lambda s: s.split("/")[-1],
            key="selected_semantic_model_path",
            on_change=reset_session_state,
        )
        st.divider()
        
        # æ—¥æœ¬èªå¿œç­”ã®æœ‰åŠ¹/ç„¡åŠ¹ã‚’é¸æŠ
        st.checkbox(
            "æ—¥æœ¬èªã§å›ç­”",
            value=True,
            key="japanese_response",
            help="ãƒã‚§ãƒƒã‚¯ã‚’å…¥ã‚Œã‚‹ã¨ã€ã‚¢ãƒŠãƒªã‚¹ãƒˆãŒæ—¥æœ¬èªã§å›ç­”ã—ã¾ã™ï¼ˆSnowflake TRANSLATEé–¢æ•°ã‚’ä½¿ç”¨ï¼‰"
        )
        st.divider()
        
        # ãƒœã‚¿ãƒ³ã‚’ä¸­å¤®é…ç½®
        _, btn_container, _ = st.columns([2, 6, 2])
        if btn_container.button("ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’ã‚¯ãƒªã‚¢", use_container_width=True):
            reset_session_state()


def display_initial_suggestions():
    """åˆå›è¡¨ç¤ºæ™‚ã®ã‚µã‚¸ã‚§ã‚¹ãƒˆè³ªå•ã‚’è¡¨ç¤º"""
    st.subheader("ğŸ’¡ ã“ã‚“ãªè³ªå•ãŒã§ãã¾ã™")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if st.button(SUGGESTED_QUESTIONS[0], key="initial_suggestion_1", use_container_width=True):
            process_user_input(SUGGESTED_QUESTIONS[0])
    
    with col2:
        if st.button(SUGGESTED_QUESTIONS[1], key="initial_suggestion_2", use_container_width=True):
            process_user_input(SUGGESTED_QUESTIONS[1])
    
    with col3:
        if st.button(SUGGESTED_QUESTIONS[2], key="initial_suggestion_3", use_container_width=True):
            process_user_input(SUGGESTED_QUESTIONS[2])


def handle_user_inputs():
    """ãƒãƒ£ãƒƒãƒˆã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã‹ã‚‰ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã‚’å‡¦ç†"""
    # ãƒãƒ£ãƒƒãƒˆå…¥åŠ›ã‚’å‡¦ç†
    user_input = st.chat_input("ã”è³ªå•ã‚’ã©ã†ã")
    if user_input:
        process_user_input(user_input)
    # ã‚µã‚¸ã‚§ã‚¹ãƒˆè³ªå•ã®ã‚¯ãƒªãƒƒã‚¯ã‚’å‡¦ç†
    elif st.session_state.active_suggestion is not None:
        suggestion = st.session_state.active_suggestion
        st.session_state.active_suggestion = None
        process_user_input(suggestion)


def handle_error_notifications():
    """ã‚¨ãƒ©ãƒ¼é€šçŸ¥ã‚’å‡¦ç†"""
    if st.session_state.get("fire_API_error_notify"):
        st.toast("APIã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸï¼", icon="ğŸš¨")
        st.session_state["fire_API_error_notify"] = False


def enhance_user_prompt(prompt: str) -> str:
    """
    ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«æ—¥æœ¬èªå¿œç­”ã®æŒ‡ç¤ºã‚’è¿½åŠ 
    
    Args:
        prompt (str): å…ƒã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        
    Returns:
        str: æ‹¡å¼µã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
    """
    if not st.session_state.get("japanese_response", True):
        return prompt
    
    # æ—¥æœ¬èªã§ã®å›ç­”ã‚’è¦æ±‚ã™ã‚‹æŒ‡ç¤ºã‚’è¿½åŠ 
    japanese_instruction = """

ã€é‡è¦ã€‘ä»¥ä¸‹ã®ç‚¹ã«å¾“ã£ã¦å›ç­”ã—ã¦ãã ã•ã„ï¼š
1. å›ç­”ã¯å¿…ãšæ—¥æœ¬èªã§è¡Œã£ã¦ãã ã•ã„
2. ãƒ‡ãƒ¼ã‚¿åˆ†æã®çµæœã‚„èª¬æ˜ã¯æ—¥æœ¬èªã§åˆ†ã‹ã‚Šã‚„ã™ãè¨˜è¿°ã—ã¦ãã ã•ã„
3. æ•°å€¤ã‚„çµ±è¨ˆæƒ…å ±ã«ã¯é©åˆ‡ãªæ—¥æœ¬èªã®èª¬æ˜ã‚’æ·»ãˆã¦ãã ã•ã„
4. ææ¡ˆã‚„ã‚¤ãƒ³ã‚µã‚¤ãƒˆã‚‚æ—¥æœ¬èªã§æä¾›ã—ã¦ãã ã•ã„
5. å°‚é–€ç”¨èªã¯æ—¥æœ¬èªã§èª¬æ˜ã—ã¦ãã ã•ã„

è³ªå•: """
    
    return japanese_instruction + prompt


def process_user_input(prompt: str):
    """
    ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã‚’å‡¦ç†ã—ã€ä¼šè©±å±¥æ­´ã‚’æ›´æ–°

    Args:
        prompt (str): ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›
    """
    # æ—¥æœ¬èªå¿œç­”ã®ãŸã‚ã«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ‹¡å¼µ
    enhanced_prompt = enhance_user_prompt(prompt)
    
    # æ–°ã—ã„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä½œæˆï¼ˆè¡¨ç¤ºç”¨ã¯å…ƒã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã€APIç”¨ã¯æ‹¡å¼µãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼‰
    display_message = {
        "role": "user",
        "content": [{"type": "text", "text": prompt}],  # è¡¨ç¤ºç”¨ã¯å…ƒã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
    }
    
    api_message = {
        "role": "user", 
        "content": [{"type": "text", "text": enhanced_prompt}],  # APIç”¨ã¯æ‹¡å¼µãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
    }
    
    # è¡¨ç¤ºç”¨ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å±¥æ­´ã«è¿½åŠ 
    st.session_state.messages.append(display_message)
    with st.chat_message("user"):
        user_msg_index = len(st.session_state.messages) - 1
        display_message_content(display_message["content"], user_msg_index)

    # ã‚¢ãƒŠãƒªã‚¹ãƒˆã®å¿œç­”ã‚’å¾…ã¤é–“ã€ã‚¢ãƒŠãƒªã‚¹ãƒˆã®ãƒãƒ£ãƒƒãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å†…ã«ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹è¡¨ç¤º
    with st.chat_message("analyst"):
        with st.spinner("ã‚¢ãƒŠãƒªã‚¹ãƒˆã‹ã‚‰ã®å¿œç­”ã‚’å¾…ã£ã¦ã„ã¾ã™..."):
            time.sleep(1)
            # APIå‘¼ã³å‡ºã—ç”¨ã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æº–å‚™ï¼ˆæœ€å¾Œã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æ‹¡å¼µç‰ˆã«ç½®ãæ›ãˆï¼‰
            api_messages = st.session_state.messages[:-1] + [api_message]
            response, error_msg = get_analyst_response(api_messages)
            
            if error_msg is None:
                # æ—¥æœ¬èªç¿»è¨³ãŒæœ‰åŠ¹ãªå ´åˆã¯ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ç¿»è¨³
                content = response["message"]["content"]
                if st.session_state.get("japanese_response", True):
                    content = translate_message_content(content)
                
                analyst_message = {
                    "role": "analyst",
                    "content": content,
                    "request_id": response["request_id"],
                }
            else:
                # ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚‚ç¿»è¨³
                error_text = error_msg
                if st.session_state.get("japanese_response", True):
                    error_text = translate_to_japanese(error_msg)
                
                analyst_message = {
                    "role": "analyst",
                    "content": [{"type": "text", "text": error_text}],
                    "request_id": response["request_id"],
                }
                st.session_state["fire_API_error_notify"] = True
            st.session_state.messages.append(analyst_message)
            st.rerun()


def get_analyst_response(messages: List[Dict]) -> Tuple[Dict, Optional[str]]:
    """
    ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’Cortex Analyst APIã«é€ä¿¡ã—ã€å¿œç­”ã‚’è¿”ã™

    Args:
        messages (List[Dict]): ä¼šè©±å±¥æ­´

    Returns:
        Tuple[Dict, Optional[str]]: Cortex Analyst APIã‹ã‚‰ã®å¿œç­”ã¨ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    """
    # ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒœãƒ‡ã‚£ã‚’ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§æº–å‚™
    request_body = {
        "messages": messages,
        "semantic_model_file": f"@{st.session_state.selected_semantic_model_path}",
        "max_tokens": 40000,  # ãƒˆãƒ¼ã‚¯ãƒ³ä¸Šé™ã‚’10å€ç¨‹åº¦ã«æ‹¡å¤§
    }

    # Cortex Analyst APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã«POSTãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é€ä¿¡
    resp = _snowflake.send_snow_api_request(
        "POST",  # ãƒ¡ã‚½ãƒƒãƒ‰
        API_ENDPOINT,  # ãƒ‘ã‚¹
        {},  # ãƒ˜ãƒƒãƒ€ãƒ¼
        {},  # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        request_body,  # ãƒœãƒ‡ã‚£
        None,  # request_guid
        API_TIMEOUT,  # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼ˆãƒŸãƒªç§’ï¼‰
    )

    # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚ºã•ã‚ŒãŸJSONã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®æ–‡å­—åˆ—
    parsed_content = json.loads(resp["content"])

    # å¿œç­”ãŒæˆåŠŸã‹ã©ã†ã‹ã‚’ç¢ºèª
    if resp["status"] < 400:
        # å¿œç­”ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’JSONã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã¨ã—ã¦è¿”ã™
        return parsed_content, None
    else:
        # èª­ã¿ã‚„ã™ã„ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä½œæˆ
        error_msg = f"""
ğŸš¨ ã‚¢ãƒŠãƒªã‚¹ãƒˆAPIã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ ğŸš¨

* ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚³ãƒ¼ãƒ‰: `{resp['status']}`
* ãƒªã‚¯ã‚¨ã‚¹ãƒˆID: `{parsed_content.get('request_id', 'N/A')}`
* ã‚¨ãƒ©ãƒ¼ã‚³ãƒ¼ãƒ‰: `{parsed_content.get('error_code', 'N/A')}`

ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸:
{parsed_content.get('message', 'è©³ç´°ä¸æ˜')}

        """
        return parsed_content, error_msg


def display_conversation():
    """
    ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆé–“ã®ä¼šè©±å±¥æ­´ã‚’è¡¨ç¤º
    """
    for idx, message in enumerate(st.session_state.messages):
        role = message["role"]
        content = message["content"]
        with st.chat_message(role):
            display_message_content(content, idx)


def display_message_content(content: List[Dict[str, str]], message_index: int):
    """
    å˜ä¸€ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’è¡¨ç¤º

    Args:
        content (List[Dict[str, str]]): ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
        message_index (int): ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
    """
    for item in content:
        if item["type"] == "text":
            st.markdown(item["text"])
        elif item["type"] == "suggestions":
            # ã‚µã‚¸ã‚§ã‚¹ãƒˆã‚’ãƒœã‚¿ãƒ³ã¨ã—ã¦è¡¨ç¤º
            st.subheader("ğŸ’¡ é–¢é€£ã™ã‚‹è³ªå•")
            for suggestion_index, suggestion in enumerate(item["suggestions"]):
                if st.button(
                    suggestion, key=f"suggestion_{message_index}_{suggestion_index}",
                    use_container_width=True
                ):
                    st.session_state.active_suggestion = suggestion
        elif item["type"] == "sql":
            # SQLã‚¯ã‚¨ãƒªã¨çµæœã‚’è¡¨ç¤º
            display_sql_query(item["statement"], message_index)
        else:
            # å¿…è¦ã«å¿œã˜ã¦ä»–ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚¿ã‚¤ãƒ—ã‚’å‡¦ç†
            pass


@st.cache_data(show_spinner=False, max_entries=1000)  # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µã‚¤ã‚ºã‚‚æ‹¡å¤§
def get_query_exec_result(query: str) -> Tuple[Optional[pd.DataFrame], Optional[str]]:
    """
    SQLã‚¯ã‚¨ãƒªã‚’å®Ÿè¡Œã—ã€çµæœã‚’pandas DataFrameã«å¤‰æ›

    Args:
        query (str): SQLã‚¯ã‚¨ãƒª

    Returns:
        Tuple[Optional[pd.DataFrame], Optional[str]]: ã‚¯ã‚¨ãƒªçµæœã¨ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    """
    global session
    try:
        df = session.sql(query).to_pandas()
        return df, None
    except SnowparkSQLException as e:
        return None, str(e)


def display_sql_query(sql: str, message_index: int):
    """
    SQLã‚¯ã‚¨ãƒªã‚’å®Ÿè¡Œã—ã€ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã¨ãƒãƒ£ãƒ¼ãƒˆã®å½¢ã§çµæœã‚’è¡¨ç¤º

    Args:
        sql (str): SQLã‚¯ã‚¨ãƒª
        message_index (int): ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
    """

    # SQLã‚¯ã‚¨ãƒªã‚’è¡¨ç¤º
    with st.expander("SQLã‚¯ã‚¨ãƒª", expanded=False):
        st.code(sql, language="sql")

    # SQLã‚¯ã‚¨ãƒªã®çµæœã‚’è¡¨ç¤º
    with st.expander("çµæœ", expanded=True):
        with st.spinner("SQLã‚’å®Ÿè¡Œä¸­..."):
            df, err_msg = get_query_exec_result(sql)
            if df is None:
                st.error(f"ç”Ÿæˆã•ã‚ŒãŸSQLã‚¯ã‚¨ãƒªã‚’å®Ÿè¡Œã§ãã¾ã›ã‚“ã§ã—ãŸã€‚ã‚¨ãƒ©ãƒ¼: {err_msg}")
                return

            if df.empty:
                st.write("ã‚¯ã‚¨ãƒªã¯ãƒ‡ãƒ¼ã‚¿ã‚’è¿”ã—ã¾ã›ã‚“ã§ã—ãŸ")
                return

            # ã‚¯ã‚¨ãƒªçµæœã‚’2ã¤ã®ã‚¿ãƒ–ã§è¡¨ç¤º
            data_tab, chart_tab = st.tabs(["ãƒ‡ãƒ¼ã‚¿ ğŸ“„", "ãƒãƒ£ãƒ¼ãƒˆ ğŸ“ˆ"])
            with data_tab:
                st.dataframe(df, use_container_width=True)

            with chart_tab:
                display_charts_tab(df, message_index)


def display_charts_tab(df: pd.DataFrame, message_index: int) -> None:
    """
    ãƒãƒ£ãƒ¼ãƒˆã‚¿ãƒ–ã‚’è¡¨ç¤º

    Args:
        df (pd.DataFrame): ã‚¯ã‚¨ãƒªçµæœ
        message_index (int): ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
    """
    # ãƒãƒ£ãƒ¼ãƒˆã‚’æç”»ã™ã‚‹ã«ã¯å°‘ãªãã¨ã‚‚2åˆ—å¿…è¦
    if len(df.columns) >= 2:
        all_cols_set = set(df.columns)
        col1, col2 = st.columns(2)
        x_col = col1.selectbox(
            "Xè»¸", all_cols_set, key=f"x_col_select_{message_index}"
        )
        y_col = col2.selectbox(
            "Yè»¸",
            all_cols_set.difference({x_col}),
            key=f"y_col_select_{message_index}",
        )
        chart_type = st.selectbox(
            "ãƒãƒ£ãƒ¼ãƒˆã‚¿ã‚¤ãƒ—ã‚’é¸æŠ",
            options=["ç·šã‚°ãƒ©ãƒ• ğŸ“ˆ", "æ£’ã‚°ãƒ©ãƒ• ğŸ“Š"],
            key=f"chart_type_{message_index}",
        )
        if chart_type == "ç·šã‚°ãƒ©ãƒ• ğŸ“ˆ":
            st.line_chart(df.set_index(x_col)[y_col])
        elif chart_type == "æ£’ã‚°ãƒ©ãƒ• ğŸ“Š":
            st.bar_chart(df.set_index(x_col)[y_col])
    else:
        st.write("ãƒãƒ£ãƒ¼ãƒˆã®æç”»ã«ã¯å°‘ãªãã¨ã‚‚2åˆ—ãŒå¿…è¦ã§ã™")


if __name__ == "__main__":
    main()
